{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5856eb82-bde0-4493-88c9-ea970f164923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989b0edb-449d-41a3-aba7-15a90451cd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b5bb93-8576-458a-b3c3-78e14109a82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/data/experiments/exp_birds2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667b51b8-56f9-4a61-b295-49463cf00890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys                                                                             # Python system library needed to load custom functions\n",
    "import numpy as np                                                                     # for performing calculations on numerical arrays\n",
    "import pandas as pd                                                                    # home of the DataFrame construct, _the_ most important object for Data Science\n",
    "import seaborn as sns                                                                  # additional plotting library\n",
    "import matplotlib.pyplot as plt                                                        # allows creation of insightful plots\n",
    "import os                                                                              # for changing the directory\n",
    "\n",
    "import sagemaker                                                                       # dedicated sagemaker library to execute training jobs\n",
    "import boto3                                                                           # for interacting with S3 buckets\n",
    "\n",
    "from sagemaker.huggingface import HuggingFace                                           # for executing the trainig jobs\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score             # tools to understand how our model is performing\n",
    "\n",
    "#sys.path.append('')                                                               # Add the source directory to the PYTHONPATH. This allows to import local functions and modules.\n",
    "from config import DEFAULT_BUCKET, DEFAULT_REGION  \n",
    "from gdsc_utils import create_encrypted_bucket, download_and_extract_model, PROJECT_DIR # functions to create S3 buckets and to help with downloading models. Importing our root directory\n",
    "from gdsc_eval import plot_confusion_matrix                                             # function for creating confusion matrix                                     # importing the bucket name that contains data for the challenge and the default region\n",
    "os.chdir(PROJECT_DIR)                                                                   # changing our directory to root\n",
    "\n",
    "\n",
    "import logging                                                    # module for displaying relevant information in the logs\n",
    "import sys                                                        # to access to some variables used or maintained by the interpreter \n",
    "import argparse                                                   # to parse arguments from passed in the hyperparameters\n",
    "import json                                                       # to open the json file with labels\n",
    "from transformers import (                                        # required classes to perform the model training and implement early stopping\n",
    "    ASTFeatureExtractor, \n",
    "    ASTForAudioClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    EarlyStoppingCallback\n",
    ")                                    \n",
    "import torch                                                       # library to work with PyTorch tensors and to figure out if we have a GPU available\n",
    "from datasets import load_dataset, Audio, Dataset                  # required tools to create, load and process our audio dataset\n",
    "from preprocessing import preprocess_audio_arrays                  # functions to preprocess the dataset with ASTFeatureExtractor\n",
    "from gdsc_eval import compute_metrics, make_predictions            # functions to create predictions and evaluate them\n",
    "from typing import Optional                                        # for type hints\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b49612-de96-4524-a0f1-44aff55ebc17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_extractor(model_name: str, \n",
    "                          train_dataset_mean: Optional[float] = None, \n",
    "                          train_dataset_std: Optional[float] = None) -> ASTFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Retrieves a feature extractor for audio signal processing.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the pre-trained model to use.\n",
    "        train_dataset_mean (float, optional): The mean value of the training dataset. Defaults to None.\n",
    "        train_dataset_std (float, optional): The standard deviation of the training dataset. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        ASTFeatureExtractor: An instance of the ASTFeatureExtractor class.\n",
    "\n",
    "    \"\"\"\n",
    "    if all((train_dataset_mean, train_dataset_std)):\n",
    "        feature_extractor = ASTFeatureExtractor.from_pretrained(model_name, mean=train_dataset_mean, std=train_dataset_std, max_length=1024)\n",
    "        logger.info(f\" feature extractor loaded with dataset mean: {train_dataset_mean} and standard deviation: {train_dataset_std}\")\n",
    "    else:\n",
    "        feature_extractor = ASTFeatureExtractor.from_pretrained(model_name)\n",
    "        logger.info(\" at least one of the optional arguments (mean, std) is missing\")\n",
    "        logger.info(f\" feature extractor loaded with default dataset mean: {feature_extractor.mean} and standard deviation: {feature_extractor.std}\")\n",
    "        \n",
    "    return feature_extractor\n",
    "\n",
    "def preprocess_data_for_training(\n",
    "    dataset_path: str,\n",
    "    sampling_rate: int,\n",
    "    feature_extractor: ASTFeatureExtractor,\n",
    "    fe_batch_size: int,\n",
    "    dataset_name: str,\n",
    "    shuffle: bool = False,\n",
    "    extract_file_name: bool = True) -> Dataset:\n",
    "    \"\"\"\n",
    "    Preprocesses audio data for training.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): The path to the dataset.\n",
    "        sampling_rate (int): The desired sampling rate for the audio.\n",
    "        feature_extractor (ASTFeatureExtractor): The feature extractor to use for preprocessing.\n",
    "        fe_batch_size (int): The batch size for feature extraction.\n",
    "        dataset_name (str, optional): The name of the dataset. Defaults to None.\n",
    "        shuffle (bool, optional): Whether to shuffle the dataset. Defaults to False.\n",
    "        extract_file_name (bool, optional): Whether to extract paths from audio features. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        dataset: The preprocessed dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"audiofolder\", data_dir=dataset_path).get('train') # loading the dataset\n",
    "    \n",
    "    # perform shuffle if specified\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(seed=42)\n",
    "        \n",
    "    logger.info(f\" loaded {dataset_name} dataset length is: {len(dataset)}\")\n",
    "\n",
    "    if extract_file_name:\n",
    "        remove_metadata = lambda x: x.endswith(\".wav\")\n",
    "        extract_file_name = lambda x: x.split('/')[-1]\n",
    "\n",
    "        dataset_paths = list(dataset.info.download_checksums.keys())\n",
    "        dataset_paths = list(filter(remove_metadata, dataset_paths))\n",
    "        dataset_paths = list(map(extract_file_name, dataset_paths))\n",
    "        dataset = dataset.add_column(\"file_name\", dataset_paths)\n",
    "\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
    "    \n",
    "    logger.info(f\" {dataset_name} dataset sampling rate casted to: {sampling_rate}\")\n",
    "\n",
    "    dataset_encoded = dataset.map(\n",
    "        lambda x: preprocess_audio_arrays(x, 'audio', 'array', feature_extractor),\n",
    "        remove_columns=\"audio\",\n",
    "        batched=True,\n",
    "        batch_size=fe_batch_size\n",
    "    )\n",
    "    \n",
    "    logger.info(f\" done extracting features for {dataset_name} dataset\")\n",
    "    \n",
    "    return dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c55a254c-413d-4e0e-a143-d3561cb38b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# hyperparameters sent from our jupyter notebook are passed as command-line arguments to the script\n",
    "# preprocessing hyperparameters\n",
    "parser.add_argument(\"--sampling_rate\", type=int, default=22050)                        # sampling rate to which we will cast audio files\n",
    "parser.add_argument(\"--fe_batch_size\", type=int, default=32)                           # feature extractor batch size\n",
    "parser.add_argument(\"--train_dataset_mean\", type=float, default=-8.076275929131292)                  # mean value of spectrograms of our data\n",
    "parser.add_argument(\"--train_dataset_std\", type=float, default=3.984092920341275)                   # standard deviation value of spectrograms of our resampled data\n",
    "# parser.add_argument(\"--train_dataset_mean\", type=float, default=-8.141991150530815)                  # mean value of spectrograms of our data\n",
    "# parser.add_argument(\"--train_dataset_std\", type=float, default=4.095692486358449)                   # standard deviation value of spectrograms of our resampled data\n",
    "\n",
    "# training hyperparameters\n",
    "parser.add_argument(\"--model_name\", type=str)                                          # name of the pretrained model from HuggingFace\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=2e-5)                       # learning rate\n",
    "parser.add_argument(\"--epochs\", type=int, default=4)                                   # number of training epochs \n",
    "parser.add_argument(\"--train_batch_size\", type=int, default=4)                        # training batch size\n",
    "parser.add_argument(\"--eval_batch_size\", type=int, default=64)                         # evaluation batch size\n",
    "parser.add_argument(\"--patience\", type=int, default=2)                                 # early stopping - how many epoch without improvement will stop the training \n",
    "# parser.add_argument(\"--data_channel\", type=str, default=os.environ[\"SM_CHANNEL_DATA\"]) # directory where input data from S3 is stored\n",
    "parser.add_argument(\"--train_dir\", type=str, default=\"train\")                          # folder name with training data\n",
    "parser.add_argument(\"--val_dir\", type=str, default=\"val\")                              # folder name with validation data\n",
    "parser.add_argument(\"--test_dir\", type=str, default=\"test\")                            # folder name with test data\n",
    "# parser.add_argument(\"--output_dir\", type=str, default=os.environ['SM_MODEL_DIR'])      # output directory. This directory will be saved in the S3 bucket\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()                    # parsing arguments from the notebook\n",
    "\n",
    "\n",
    "# train_path = f\"{args.data_channel}/{args.train_dir}\"   # directory of our training dataset on the instance\n",
    "# val_path = f\"{args.data_channel}/{args.val_dir}\"       # directory of our validation dataset on the instance\n",
    "# test_path = f\"{args.data_channel}/{args.test_dir}\"     # directory of our test dataset on the instance\n",
    "\n",
    "# Set up logging which allows to print information in logs\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.getLevelName(\"INFO\"),\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a1ee0c-1c6a-4d7d-b0fa-28b660bc3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/data_small/train'\n",
    "val_path = 'data/data_small/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "691f49e4-69bd-45c7-b9f2-12fbcd0f0302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'data/data_small/labels.json', 'r') as f:\n",
    "        labels = json.load(f)\n",
    "    \n",
    "# Create mapping from label to id and id to label\n",
    "label2id, id2label = dict(), dict()\n",
    "for k, v in labels.items():\n",
    "    label2id[k] = str(v)\n",
    "    id2label[str(v)] = k\n",
    "\n",
    "num_labels = len(label2id)  # define number of labels\n",
    "output_dir='models/efficientnet2v4',                # directory for saving model checkpoints and logs\n",
    "args.model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24699f62-1a13-4587-bd7b-d9b4cdc8dac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057f290d19774b91bb7a11adc3445bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:31:15,492 - datasets.builder - WARNING - Found cached dataset audiofolder (/root/.cache/huggingface/datasets/audiofolder/default-4ea904e8a4f39112/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55d2aa213214436b4fb0a33bae529ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:31:15,508 - datasets.arrow_dataset - WARNING - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/audiofolder/default-4ea904e8a4f39112/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc/cache-8d133f78b720c65d.arrow\n",
      "2023-07-10 20:31:15,511 - __main__ - INFO -  loaded train dataset length is: 176\n",
      "2023-07-10 20:31:15,515 - __main__ - INFO -  train dataset sampling rate casted to: 22050\n",
      "2023-07-10 20:31:15,529 - datasets.arrow_dataset - WARNING - Loading cached processed dataset at /root/.cache/huggingface/datasets/audiofolder/default-4ea904e8a4f39112/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc/cache-2cdba842eef158bb.arrow\n",
      "2023-07-10 20:31:15,530 - __main__ - INFO -  done extracting features for train dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8addf820f94668953f6640f5b9d8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:31:15,683 - datasets.builder - WARNING - Found cached dataset audiofolder (/root/.cache/huggingface/datasets/audiofolder/default-99123276a0f5ab0b/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f9793c760049999ec5f75a222353ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10 20:31:15,699 - __main__ - INFO -  loaded validation dataset length is: 66\n",
      "2023-07-10 20:31:15,715 - __main__ - INFO -  validation dataset sampling rate casted to: 22050\n",
      "2023-07-10 20:31:15,726 - datasets.arrow_dataset - WARNING - Loading cached processed dataset at /root/.cache/huggingface/datasets/audiofolder/default-99123276a0f5ab0b/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc/cache-96be9f0276ba55fe.arrow\n",
      "2023-07-10 20:31:15,726 - __main__ - INFO -  done extracting features for validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ASTForAudioClassification were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
      "- classifier.dense.weight: found shape torch.Size([527, 768]) in the checkpoint and torch.Size([66, 768]) in the model instantiated\n",
      "- classifier.dense.bias: found shape torch.Size([527]) in the checkpoint and torch.Size([66]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# feature_extractor = get_feature_extractor(args.model_name, args.train_dataset_mean, args.train_dataset_std)\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(args.model_name, do_normalize=False)\n",
    "\n",
    "# creating train and validation datasets\n",
    "train_dataset_encoded = preprocess_data_for_training(dataset_path=train_path, sampling_rate=args.sampling_rate, feature_extractor=feature_extractor,\n",
    "                                                     fe_batch_size=args.fe_batch_size, dataset_name=\"train\", shuffle=True, extract_file_name=False)\n",
    "\n",
    "val_dataset_encoded = preprocess_data_for_training(dataset_path=val_path, sampling_rate=args.sampling_rate, feature_extractor=feature_extractor,\n",
    "                                                   fe_batch_size=args.fe_batch_size, dataset_name=\"validation\")\n",
    "\n",
    "# Download model from model hub\n",
    "model = ASTForAudioClassification.from_pretrained(args.model_name, num_labels=num_labels, label2id=label2id, id2label=id2label, ignore_mismatched_sizes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "686c9025-e19c-4f4c-b62f-77cb147e22ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_values'],\n",
       "    num_rows: 176\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd0411cb-ec61-4653-8f09-25ef10e3e239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_train_data = np.array([train_dataset_encoded[i]['input_values'] for i in range(len(train_dataset_encoded))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decfb195-345c-45e5-be33-32c1b4cff901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_train_data = abs(input_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd430341-f50f-4e74-a6ed-08e5d769cdb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_train_data = np.repeat(input_train_data[..., np.newaxis], 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10fe90f-6762-4afb-9787-b47939cd5c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 1024, 128, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4217b7b2-c397-4f35-b6a4-a505ac86406d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, EfficientNetForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c732f665-3b30-4155-8c43-3df6c3f9694b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"google/efficientnet-b4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "950bb734-1192-4381-b931-463ce08cffa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_norm = (input_train_data-np.min(input_train_data))/(np.max(input_train_data)-np.min(input_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154a6ad3-2ba0-4500-9e2b-d04d79f5664a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = image_processor(x_norm, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc9dfe22-1a87-4b65-86ae-3165d683776a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_input = inputs['pixel_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f83730d7-f199-489a-abec-07b9d229be70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_input = example_input[None, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f385964-d22e-409d-ab4d-f63de42f0d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dct = {'pixel_values' : example_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f0c2770-be5d-4f48-bc7c-bfa5a579ef62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
       "           ...,\n",
       "           [ 2.2489,  2.2489,  2.2489,  ..., -0.6965, -0.6965, -0.6965],\n",
       "           [ 1.3755,  1.3755,  1.3755,  ..., -1.9980, -1.9980, -1.9980],\n",
       "           [ 2.2489,  2.2489,  2.2489,  ..., -0.7137, -0.7137, -0.7137]],\n",
       " \n",
       "          [[ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
       "           ...,\n",
       "           [ 2.4286,  2.4286,  2.4286,  ..., -0.5826, -0.5826, -0.5826],\n",
       "           [ 1.5357,  1.5357,  1.5357,  ..., -1.9132, -1.9132, -1.9132],\n",
       "           [ 2.4286,  2.4286,  2.4286,  ..., -0.6001, -0.6001, -0.6001]],\n",
       " \n",
       "          [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
       "           ...,\n",
       "           [ 2.6400,  2.6400,  2.6400,  ..., -0.3578, -0.3578, -0.3578],\n",
       "           [ 1.7511,  1.7511,  1.7511,  ..., -1.6824, -1.6824, -1.6824],\n",
       "           [ 2.6400,  2.6400,  2.6400,  ..., -0.3753, -0.3753, -0.3753]]]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e70ae863-49a5-4c9b-a7fb-78efd42bfa1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 380, 380])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db6b03ad-f324-4804-927a-4c867e12a272",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EfficientNetForImageClassification were not initialized from the model checkpoint at google/efficientnet-b4 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 1792]) in the checkpoint and torch.Size([66, 1792]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([66]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNetForImageClassification.from_pretrained(\"google/efficientnet-b4\", num_labels=66, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476690e1-6758-4392-afea-e2f117931e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7eef9ac-6ea6-4982-a487-679b5b2fd969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:33<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for i in tqdm(range(176)):\n",
    "    example_input = inputs['pixel_values'][i]\n",
    "    example_input = example_input[None, :, :, :]\n",
    "    dct = {'pixel_values' : example_input}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**dct).logits\n",
    "        predicted_label = logits.argmax(-1).item()\n",
    "        labels.append(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f90e4c45-d6b4-48e5-b84b-59c4b6b33bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0156, 0.0150, 0.0140, 0.0159, 0.0196, 0.0144, 0.0108, 0.0139, 0.0159,\n",
       "         0.0151, 0.0147, 0.0174, 0.0188, 0.0174, 0.0176, 0.0161, 0.0122, 0.0153,\n",
       "         0.0159, 0.0157, 0.0132, 0.0129, 0.0195, 0.0130, 0.0150, 0.0155, 0.0128,\n",
       "         0.0163, 0.0145, 0.0144, 0.0155, 0.0186, 0.0109, 0.0176, 0.0152, 0.0151,\n",
       "         0.0177, 0.0141, 0.0163, 0.0131, 0.0194, 0.0140, 0.0175, 0.0091, 0.0166,\n",
       "         0.0145, 0.0140, 0.0134, 0.0115, 0.0122, 0.0164, 0.0158, 0.0110, 0.0175,\n",
       "         0.0163, 0.0134, 0.0123, 0.0136, 0.0172, 0.0186, 0.0145, 0.0140, 0.0163,\n",
       "         0.0163, 0.0156, 0.0166]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbc6f7ec-eda4-4a3f-8d79-7c10fc180881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_label = logits.argmax(-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b934856-63ef-4704-ac22-6332c5b5b08b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a675bc6-b182-4cf2-9e71-ae27fbde55f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.rnd = np.random.RandomState(0)\n",
    "\n",
    "        #self.x_data = torch.tensor(train_dataset_encoded[:]['input_values'], dtype=torch.float32).to(device)\n",
    "        self.x_data = np.array([train_dataset_encoded[i]['input_values'] for i in range(len(train_dataset_encoded))])\n",
    "        self.x_data = abs(self.x_data)\n",
    "        self.x_data = np.repeat(self.x_data[..., np.newaxis], 3, axis=-1)\n",
    "        self.x_data = (self.x_data-np.min(self.x_data))/(np.max(self.x_data)-np.min(self.x_data))\n",
    "        self.y_data = torch.tensor(train_dataset_encoded[:]['label'], dtype=torch.int64).to(device) \n",
    "\n",
    "        self.n = len(self.x_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "#TODO: create better triplet selection\n",
    "    def __getitem__(self, idx):\n",
    "        y = self.y_data[idx]\n",
    "        x = self.x_data[idx]\n",
    "        #x = x.resize_(1, 1024, 128)\n",
    "        #x = x.expand(3, 1024, 128)\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b3c5ab9-8a5b-4032-84c5-e02f7d688104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import EfficientNetImageProcessor, EfficientNetForImageClassification\n",
    "\n",
    "class ClassificationNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationNet, self).__init__()  # pre 3.3 syntax\n",
    "        self.model = EfficientNetForImageClassification.from_pretrained(\"google/efficientnet-b4\", num_labels=66, ignore_mismatched_sizes=True)\n",
    "        self.image_processor = EfficientNetImageProcessor.from_pretrained(\"google/efficientnet-b4\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        inputs = self.image_processor(x, return_tensors=\"pt\")\n",
    "        output = self.model(x).logits\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390e753-e7c7-4b05-bfbe-297874f8c483",
   "metadata": {},
   "source": [
    "### TRAIN SIAMESE PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0c9df79-5b4a-4a29-90c5-b43242ee5a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions2(examples: torch.Tensor, \n",
    "                     model: torch.nn.Module, \n",
    "                     device,\n",
    "                     labels: torch.Tensor = None):\n",
    "    model = model.to(device)\n",
    "    examples = torch.tensor(examples, dtype=torch.float32).to(device)\n",
    "    examples = examples.resize_(examples.shape[0], 1,examples.shape[-2],examples.shape[-1])\n",
    "    examples = examples.expand(examples.shape[0], 3,examples.shape[-2],examples.shape[-1])\n",
    "    labels = torch.tensor(labels, dtype=torch.int64).to(device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(examples)\n",
    "    predicted_class_id = [str(torch.argmax(item).item()) for item in logits]\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        loss = torch.nn.functional.cross_entropy(logits.view(-1, 66), labels.to(device).view(-1), reduction=\"none\")\n",
    "        loss = loss.view(len(examples), -1).cpu().numpy()\n",
    "\n",
    "        return {'predicted_class_id': predicted_class_id, 'loss': loss, 'logits': logits}\n",
    "    else:\n",
    "        return {'predicted_class_id': predicted_class_id}\n",
    "\n",
    "    \n",
    "def compute_metrics(pred, labels):\n",
    "    # labels = pred.label_ids\n",
    "    # preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred, average=\"macro\")\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9cfc2d-945b-4ca4-abaf-55eba03d9c0f",
   "metadata": {},
   "source": [
    "### TRAIN CLASSIFICATION PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25ab42e4-e2ab-4284-801d-48fe26dc52c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EfficientNetForImageClassification were not initialized from the model checkpoint at google/efficientnet-b4 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 1792]) in the checkpoint and torch.Size([66, 1792]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([66]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_313/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">810896214.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_313/810896214.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_313/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2533542190.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_313/2533542190.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/efficientnet/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_efficientnet.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">618</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">615 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">616 │   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">617 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>618 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.efficientnet(pixel_values, output_hidden_states=output_hidden_sta   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">619 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">620 │   │   </span>pooled_output = outputs.pooler_output <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">621 │   │   </span>pooled_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dropout(pooled_output)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/efficientnet/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_efficientnet.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">552</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">549 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> pixel_values <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">550 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"You have to specify pixel_values\"</span>)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">551 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>552 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>embedding_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embeddings(pixel_values)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">553 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">554 │   │   </span>encoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoder(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">555 │   │   │   </span>embedding_output,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/efficientnet/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_efficientnet.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, pixel_values: torch.Tensor) -&gt; torch.Tensor:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   </span>features = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding(pixel_values)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>features = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.convolution(features)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   │   </span>features = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.batchnorm(features)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   │   </span>features = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.activation(features)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">463</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 460 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 461 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 462 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 463 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._conv_forward(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 464 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 465 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">Conv3d</span>(_ConvNd):                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 466 │   </span><span style=\"color: #ff0000; text-decoration-color: #ff0000\">__doc__</span> = <span style=\"color: #808000; text-decoration-color: #808000\">r\"\"\"Applies a 3D convolution over an input signal composed of several inpu</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">459</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_conv_forward</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 456 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv2d(F.pad(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reversed_padding_repeated_twice, mode=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">sel</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 457 │   │   │   │   │   │   │   </span>weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 458 │   │   │   │   │   │   │   </span>_pair(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 459 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.conv2d(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, weight, bias, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.stride,                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 460 │   │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dilation, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.groups)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 461 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 462 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>Given <span style=\"color: #808000; text-decoration-color: #808000\">groups</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, weight of size <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span>, expected input<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">129</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">]</span> to have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> channels, but\n",
       "got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span> channels instead\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_313/\u001b[0m\u001b[1;33m810896214.py\u001b[0m:\u001b[94m17\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_313/810896214.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_313/\u001b[0m\u001b[1;33m2533542190.py\u001b[0m:\u001b[94m11\u001b[0m in \u001b[92mforward\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_313/2533542190.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/efficientnet/\u001b[0m\u001b[1;33mmodeling_efficientnet.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m618\u001b[0m in \u001b[92mforward\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m615 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m616 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m617 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m618 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.efficientnet(pixel_values, output_hidden_states=output_hidden_sta   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m619 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m620 \u001b[0m\u001b[2m│   │   \u001b[0mpooled_output = outputs.pooler_output \u001b[94mif\u001b[0m return_dict \u001b[94melse\u001b[0m outputs[\u001b[94m1\u001b[0m]               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m621 \u001b[0m\u001b[2m│   │   \u001b[0mpooled_output = \u001b[96mself\u001b[0m.dropout(pooled_output)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/efficientnet/\u001b[0m\u001b[1;33mmodeling_efficientnet.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m552\u001b[0m in \u001b[92mforward\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m549 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m pixel_values \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m550 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mYou have to specify pixel_values\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m551 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m552 \u001b[2m│   │   \u001b[0membedding_output = \u001b[96mself\u001b[0m.embeddings(pixel_values)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m553 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m554 \u001b[0m\u001b[2m│   │   \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m555 \u001b[0m\u001b[2m│   │   │   \u001b[0membedding_output,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/efficientnet/\u001b[0m\u001b[1;33mmodeling_efficientnet.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mforward\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, pixel_values: torch.Tensor) -> torch.Tensor:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0mfeatures = \u001b[96mself\u001b[0m.padding(pixel_values)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   \u001b[0mfeatures = \u001b[96mself\u001b[0m.convolution(features)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   \u001b[0mfeatures = \u001b[96mself\u001b[0m.batchnorm(features)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   \u001b[0mfeatures = \u001b[96mself\u001b[0m.activation(features)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mconv.py\u001b[0m:\u001b[94m463\u001b[0m in \u001b[92mforward\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 460 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 461 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 462 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 463 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._conv_forward(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.bias)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 464 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 465 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mConv3d\u001b[0m(_ConvNd):                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 466 \u001b[0m\u001b[2m│   \u001b[0m\u001b[91m__doc__\u001b[0m = \u001b[33mr\u001b[0m\u001b[33m\"\"\"\u001b[0m\u001b[33mApplies a 3D convolution over an input signal composed of several inpu\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mconv.py\u001b[0m:\u001b[94m459\u001b[0m in \u001b[92m_conv_forward\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 456 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m F.conv2d(F.pad(\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m._reversed_padding_repeated_twice, mode=\u001b[96msel\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 457 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mweight, bias, \u001b[96mself\u001b[0m.stride,                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 458 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m_pair(\u001b[94m0\u001b[0m), \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 459 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.conv2d(\u001b[96minput\u001b[0m, weight, bias, \u001b[96mself\u001b[0m.stride,                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 460 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.padding, \u001b[96mself\u001b[0m.dilation, \u001b[96mself\u001b[0m.groups)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 461 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 462 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mGiven \u001b[33mgroups\u001b[0m=\u001b[1;36m1\u001b[0m, weight of size \u001b[1m[\u001b[0m\u001b[1;36m48\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m, expected input\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m1024\u001b[0m, \u001b[1;36m129\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m to have \u001b[1;36m3\u001b[0m channels, but\n",
       "got \u001b[1;36m1024\u001b[0m channels instead\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn_rate = 1e-3\n",
    "max_epochs = 10\n",
    "ep_log_interval = 1\n",
    "batch_size_class = 8\n",
    "\n",
    "train_class_ds = ClassificationDataset()\n",
    "train_class_ldr = torch.utils.data.DataLoader(train_class_ds, batch_size=batch_size_class, shuffle=True)\n",
    "\n",
    "classification_net = ClassificationNet().to(device) #pass net.model - siamese model\n",
    "optimizer_class = torch.optim.Adam(classification_net.parameters(), lr=lrn_rate)\n",
    "categorical_crossentropy = torch.nn.functional.cross_entropy\n",
    "\n",
    "for epoch in range(0, max_epochs):\n",
    "    ep_loss = 0  # for one full epoch\n",
    "    for (batch_idx, batch) in tqdm(enumerate(train_class_ldr)):\n",
    "        X, y = batch\n",
    "        output = classification_net(X)\n",
    "\n",
    "        optimizer_class.zero_grad()       # reset gradients\n",
    "        loss_val = categorical_crossentropy(output, y)\n",
    "\n",
    "        ep_loss += loss_val.item()  # accumulate loss\n",
    "        loss_val.backward()         # compute grads\n",
    "        optimizer_class.step()            # update weights\n",
    "    if epoch % ep_log_interval == 0:\n",
    "        print(\"epoch = %4d  |  loss = %10.4f\" % (epoch, ep_loss))\n",
    "        val_dataset_encoded2 = val_dataset_encoded.map(lambda x: make_predictions2(x['input_values'], classification_net, device, x['label']), batched=True, batch_size=8, remove_columns=\"input_values\")\n",
    "        print(compute_metrics([int(i) for i in val_dataset_encoded2[:]['predicted_class_id']], val_dataset_encoded2[:]['label']))\n",
    "    print(\"Done \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bdee6a6-0119-4f5c-a274-1f5f718a520f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/66 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_dataset_encoded2 = val_dataset_encoded.map(lambda x: make_predictions2(x['input_values'], classification_net, device, x['label']), batched=True, batch_size=4, remove_columns=\"input_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49cd158c-1676-46f7-9a87-debcc339bf13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5909090909090909,\n",
       " 'f1': 0.4952380952380952,\n",
       " 'precision': 0.4532828282828283,\n",
       " 'recall': 0.5909090909090909}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics([int(i) for i in val_dataset_encoded2[:]['predicted_class_id']], val_dataset_encoded2[:]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d6e81cd-f7b0-4819-97f9-419232db13d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-15.9424, -15.9424, -15.2467,  ...,  -9.9298, -10.5248, -14.6571],\n",
       "          [-15.9424, -15.9424, -15.9424,  ...,  -9.9403, -11.0747, -14.0391],\n",
       "          [-15.9424, -15.9424, -15.3227,  ...,  -8.6226, -10.2443, -15.4034],\n",
       "          ...,\n",
       "          [-15.9424, -15.9424, -15.9424,  ...,  -9.4018, -11.1095, -13.0079],\n",
       "          [-15.9424, -15.9424, -15.5424,  ...,  -9.5473, -11.4716, -13.6956],\n",
       "          [-15.8215, -15.9424, -15.4332,  ...,  -9.7442, -11.2408, -15.4254]],\n",
       "\n",
       "         [[-15.9424, -15.9424, -15.2467,  ...,  -9.9298, -10.5248, -14.6571],\n",
       "          [-15.9424, -15.9424, -15.9424,  ...,  -9.9403, -11.0747, -14.0391],\n",
       "          [-15.9424, -15.9424, -15.3227,  ...,  -8.6226, -10.2443, -15.4034],\n",
       "          ...,\n",
       "          [-15.9424, -15.9424, -15.9424,  ...,  -9.4018, -11.1095, -13.0079],\n",
       "          [-15.9424, -15.9424, -15.5424,  ...,  -9.5473, -11.4716, -13.6956],\n",
       "          [-15.8215, -15.9424, -15.4332,  ...,  -9.7442, -11.2408, -15.4254]],\n",
       "\n",
       "         [[-15.9424, -15.9424, -15.2467,  ...,  -9.9298, -10.5248, -14.6571],\n",
       "          [-15.9424, -15.9424, -15.9424,  ...,  -9.9403, -11.0747, -14.0391],\n",
       "          [-15.9424, -15.9424, -15.3227,  ...,  -8.6226, -10.2443, -15.4034],\n",
       "          ...,\n",
       "          [-15.9424, -15.9424, -15.9424,  ...,  -9.4018, -11.1095, -13.0079],\n",
       "          [-15.9424, -15.9424, -15.5424,  ...,  -9.5473, -11.4716, -13.6956],\n",
       "          [-15.8215, -15.9424, -15.4332,  ...,  -9.7442, -11.2408, -15.4254]]],\n",
       "\n",
       "\n",
       "        [[[-14.3185, -15.9424, -14.1563,  ...,  -8.1495, -10.2782, -13.7704],\n",
       "          [-14.1807, -15.9424, -14.2366,  ...,  -8.1326,  -9.4059, -11.9314],\n",
       "          [-14.1865, -15.9424, -14.8054,  ...,  -9.2379,  -9.4263, -12.0563],\n",
       "          ...,\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "\n",
       "         [[-14.3185, -15.9424, -14.1563,  ...,  -8.1495, -10.2782, -13.7704],\n",
       "          [-14.1807, -15.9424, -14.2366,  ...,  -8.1326,  -9.4059, -11.9314],\n",
       "          [-14.1865, -15.9424, -14.8054,  ...,  -9.2379,  -9.4263, -12.0563],\n",
       "          ...,\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "\n",
       "         [[-14.3185, -15.9424, -14.1563,  ...,  -8.1495, -10.2782, -13.7704],\n",
       "          [-14.1807, -15.9424, -14.2366,  ...,  -8.1326,  -9.4059, -11.9314],\n",
       "          [-14.1865, -15.9424, -14.8054,  ...,  -9.2379,  -9.4263, -12.0563],\n",
       "          ...,\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "          [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ -7.2456,  -8.6843,  -5.2409,  ...,  -3.7438,  -4.8964,  -8.8143],\n",
       "          [ -6.1589,  -7.8559,  -4.4125,  ...,  -2.9118,  -5.8744,  -7.8823],\n",
       "          [ -6.1450, -11.4795,  -8.0361,  ...,  -3.3571,  -4.5487,  -7.9537],\n",
       "          ...,\n",
       "          [ -6.4359,  -8.3336,  -4.8902,  ...,  -1.5484,  -3.9826,  -6.7507],\n",
       "          [ -5.0711,  -8.1360,  -4.6926,  ...,  -2.8111,  -3.7216,  -7.4856],\n",
       "          [ -5.3678,  -7.8902,  -4.4468,  ...,  -2.6509,  -3.1477,  -5.3631]],\n",
       "\n",
       "         [[ -7.2456,  -8.6843,  -5.2409,  ...,  -3.7438,  -4.8964,  -8.8143],\n",
       "          [ -6.1589,  -7.8559,  -4.4125,  ...,  -2.9118,  -5.8744,  -7.8823],\n",
       "          [ -6.1450, -11.4795,  -8.0361,  ...,  -3.3571,  -4.5487,  -7.9537],\n",
       "          ...,\n",
       "          [ -6.4359,  -8.3336,  -4.8902,  ...,  -1.5484,  -3.9826,  -6.7507],\n",
       "          [ -5.0711,  -8.1360,  -4.6926,  ...,  -2.8111,  -3.7216,  -7.4856],\n",
       "          [ -5.3678,  -7.8902,  -4.4468,  ...,  -2.6509,  -3.1477,  -5.3631]],\n",
       "\n",
       "         [[ -7.2456,  -8.6843,  -5.2409,  ...,  -3.7438,  -4.8964,  -8.8143],\n",
       "          [ -6.1589,  -7.8559,  -4.4125,  ...,  -2.9118,  -5.8744,  -7.8823],\n",
       "          [ -6.1450, -11.4795,  -8.0361,  ...,  -3.3571,  -4.5487,  -7.9537],\n",
       "          ...,\n",
       "          [ -6.4359,  -8.3336,  -4.8902,  ...,  -1.5484,  -3.9826,  -6.7507],\n",
       "          [ -5.0711,  -8.1360,  -4.6926,  ...,  -2.8111,  -3.7216,  -7.4856],\n",
       "          [ -5.3678,  -7.8902,  -4.4468,  ...,  -2.6509,  -3.1477,  -5.3631]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-15.2042, -15.7330, -12.2896,  ...,  -4.1572,  -5.1140,  -8.1090],\n",
       "          [-13.1474, -15.9424, -14.2869,  ...,  -4.4947,  -5.0803,  -8.3865],\n",
       "          [-12.3686, -15.1469, -11.7035,  ...,  -4.2969,  -5.0118,  -7.5769],\n",
       "          ...,\n",
       "          [-12.3280, -15.4278, -11.9844,  ...,  -3.4852,  -4.2844,  -7.0046],\n",
       "          [-13.6056, -15.9424, -12.5561,  ...,  -2.4578,  -4.6850,  -6.5612],\n",
       "          [-12.6064, -15.0328, -11.5894,  ...,  -3.2105,  -2.7524,  -5.0133]],\n",
       "\n",
       "         [[-15.2042, -15.7330, -12.2896,  ...,  -4.1572,  -5.1140,  -8.1090],\n",
       "          [-13.1474, -15.9424, -14.2869,  ...,  -4.4947,  -5.0803,  -8.3865],\n",
       "          [-12.3686, -15.1469, -11.7035,  ...,  -4.2969,  -5.0118,  -7.5769],\n",
       "          ...,\n",
       "          [-12.3280, -15.4278, -11.9844,  ...,  -3.4852,  -4.2844,  -7.0046],\n",
       "          [-13.6056, -15.9424, -12.5561,  ...,  -2.4578,  -4.6850,  -6.5612],\n",
       "          [-12.6064, -15.0328, -11.5894,  ...,  -3.2105,  -2.7524,  -5.0133]],\n",
       "\n",
       "         [[-15.2042, -15.7330, -12.2896,  ...,  -4.1572,  -5.1140,  -8.1090],\n",
       "          [-13.1474, -15.9424, -14.2869,  ...,  -4.4947,  -5.0803,  -8.3865],\n",
       "          [-12.3686, -15.1469, -11.7035,  ...,  -4.2969,  -5.0118,  -7.5769],\n",
       "          ...,\n",
       "          [-12.3280, -15.4278, -11.9844,  ...,  -3.4852,  -4.2844,  -7.0046],\n",
       "          [-13.6056, -15.9424, -12.5561,  ...,  -2.4578,  -4.6850,  -6.5612],\n",
       "          [-12.6064, -15.0328, -11.5894,  ...,  -3.2105,  -2.7524,  -5.0133]]],\n",
       "\n",
       "\n",
       "        [[[-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          ...,\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -11.1550, -12.3943, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.1577,  ..., -10.3698, -11.6386, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -10.2404, -12.4534, -15.8536]],\n",
       "\n",
       "         [[-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          ...,\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -11.1550, -12.3943, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.1577,  ..., -10.3698, -11.6386, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -10.2404, -12.4534, -15.8536]],\n",
       "\n",
       "         [[-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -15.9424, -15.9424, -15.9424],\n",
       "          ...,\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -11.1550, -12.3943, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.1577,  ..., -10.3698, -11.6386, -15.9424],\n",
       "          [-15.9424, -15.9424, -15.9424,  ..., -10.2404, -12.4534, -15.8536]]],\n",
       "\n",
       "\n",
       "        [[[-13.9658, -15.9424, -15.8217,  ...,  -8.2922,  -8.9908, -11.3986],\n",
       "          [ -9.4086, -12.0185,  -8.5751,  ...,  -2.9579,  -3.7156,  -7.7858],\n",
       "          [ -7.4428,  -9.6785,  -6.2351,  ...,  -3.3722,  -3.8438,  -9.1721],\n",
       "          ...,\n",
       "          [ -6.7400,  -8.9037,  -5.4603,  ...,  -3.0841,  -4.6744,  -7.8001],\n",
       "          [ -8.8276, -10.3016,  -6.8582,  ...,  -3.3283,  -4.1475,  -7.0188],\n",
       "          [ -5.4989,  -8.1304,  -4.6870,  ...,  -3.0008,  -4.7350,  -7.3830]],\n",
       "\n",
       "         [[-13.9658, -15.9424, -15.8217,  ...,  -8.2922,  -8.9908, -11.3986],\n",
       "          [ -9.4086, -12.0185,  -8.5751,  ...,  -2.9579,  -3.7156,  -7.7858],\n",
       "          [ -7.4428,  -9.6785,  -6.2351,  ...,  -3.3722,  -3.8438,  -9.1721],\n",
       "          ...,\n",
       "          [ -6.7400,  -8.9037,  -5.4603,  ...,  -3.0841,  -4.6744,  -7.8001],\n",
       "          [ -8.8276, -10.3016,  -6.8582,  ...,  -3.3283,  -4.1475,  -7.0188],\n",
       "          [ -5.4989,  -8.1304,  -4.6870,  ...,  -3.0008,  -4.7350,  -7.3830]],\n",
       "\n",
       "         [[-13.9658, -15.9424, -15.8217,  ...,  -8.2922,  -8.9908, -11.3986],\n",
       "          [ -9.4086, -12.0185,  -8.5751,  ...,  -2.9579,  -3.7156,  -7.7858],\n",
       "          [ -7.4428,  -9.6785,  -6.2351,  ...,  -3.3722,  -3.8438,  -9.1721],\n",
       "          ...,\n",
       "          [ -6.7400,  -8.9037,  -5.4603,  ...,  -3.0841,  -4.6744,  -7.8001],\n",
       "          [ -8.8276, -10.3016,  -6.8582,  ...,  -3.3283,  -4.1475,  -7.0188],\n",
       "          [ -5.4989,  -8.1304,  -4.6870,  ...,  -3.0008,  -4.7350,  -7.3830]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "GDSC (custom-gdsc/1)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:292159885427:image-version/custom-gdsc/1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:292159885427:studio-lifecycle-config/clean-trash"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
